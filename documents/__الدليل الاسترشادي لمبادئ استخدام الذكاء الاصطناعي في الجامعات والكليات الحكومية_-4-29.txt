الدليل الاسترشادي لمبادئ استخدام الذكاء الاصطناعي في الجامعات والكليات الحكومية والأهلية السعودية
--- الصفحة 1 ---
المملكة العربية السعودية
وزارة التعليم
مجلس شؤون الجامعات
الدليل الاسترشادي لمبادئ استخدام الذكاء الاصطناعي في الجامعات والكليات الحكومية والأهلية السعودية
2025م
--- الصفحة 2 ---
(صفحة تحتوي على بيانات المعاملات الإدارية وأختام التداول، ولا تتضمن محتوى علمي أو تنظيمي للدليل).
--- الصفحة 3 ---
المحتويات
المصطلحات
تمهيد
الفصل الأول: استخدام الذكاء الاصطناعي في العملية التعليمية
مبادئ استخدام الذكاء الاصطناعي في العملية التعليمية.
المعايير الاسترشادية لاستخدام الذكاء الاصطناعي في العملية التعليمية.
الأدوار والمسؤوليات عند استخدام الذكاء الاصطناعي في العملية التعليمية.
الفصل الثاني: استخدام الذكاء الاصطناعي في البحث العلمي
مبادئ استخدام الذكاء الاصطناعي في البحث العلمي.
المعايير الاسترشادية لاستخدام الذكاء الاصطناعي في البحث العلمي.
الأدوار والمسؤوليات عند استخدام الذكاء الاصطناعي في البحث العلمي.
الفصل الثالث: استخدام الذكاء الاصطناعي في الأنشطة الإدارية
مبادئ استخدام الذكاء الاصطناعي في الأنشطة الإدارية.
المعايير الاسترشادية لاستخدام الذكاء الاصطناعي في الأنشطة الإدارية.
الأدوار والمسؤوليات عند استخدام الذكاء الاصطناعي في الأنشطة الإدارية.
الفصل الرابع: المخاطر
الفصل الخامس: إرشادات استخدام الدليل
--- الصفحة 4 ---
المصطلحات
المؤسسة التعليمية: كيان منظم يعنى بتقديم خدمات التعليم بطريقة رسمية ومنهجية. وفي إطار هذه السياسة، يشمل ذلك جميع المعاهد والكليات، والجامعات، سواء كانت تابعة للقطاع العام أو الخاص.
الذكاء الاصطناعي: مجال من مجالات علوم الحاسب يركز على بناء أنظمة قادرة على أداء مهام تتطلب عادة ذكاءً بشرياً، مثل: التعلم والاستدلال والتطوير الذاتي، ويُطلق عليه أيضًا "ذكاء الآلة".
الذكاء الاصطناعي التوليدي: نوع من الذكاء الاصطناعي يمكنه إنشاء محتوى جديد مثل: النصوص والصور والأصوات والفيديوهات والأكواد البرمجية.
التعلم العميق: مجال فرعي من تعلم الآلة يستخدم عدة طبقات مخفية في الشبكات العصبية لحل المشكلات المعقدة عن طريق تحديد أهم الخصائص الأساسية للبيانات المدخلة.
معالجة اللغات الطبيعية: فرع من فروع الذكاء الاصطناعي يهتم بفهم أو توليد اللغة البشرية سواء كانت على شكل نص أو كلام.
النموذج: تمثيل لما تعلمته خوارزمية تعلم الآلة من بيانات التدريب. ويُطلق عليه أيضاً "نموذج تعلم الآلة".
حوكمة الذكاء الاصطناعي: السياسات والمبادئ والممارسات التي تضمن التطوير والاستخدام المسؤول والأخلاقي والأمن للذكاء الاصطناعي.
الشفافية وقابلية التفسير: القدرة على شرح العوامل المهمة التي تؤثر في نتائج نظام الذكاء الاصطناعي بعبارات مفهومة للإنسان، ويُطلق عليها أيضاً "ذكاء اصطناعي قابل للتفسير" أو "قابلية الشرح".
نظام دعم القرار: نظام معلومات يساعد في تقييم البدائل وحل المشكلات واتخاذ القرارات.
--- الصفحة 5 ---
تمهيد
يتضمن الدليل الاسترشادي لمبادئ استخدام الذكاء الاصطناعي في الجامعات والكليات الحكومية والأهلية السعودية إرشادات موجهة لاستخدامات الذكاء الاصطناعي (التعليمية والبحثية والإدارية) في التعليم العالي بالمواءمة مع التوجهات الاستراتيجية للمملكة العربية السعودية. ويهدف إلى المساهمة في الارتقاء بجودة التعليم العالي وضمان دمج الذكاء الاصطناعي بكفاءة في أنشطة مؤسسات التعليم العالي بطريقة فعالة ومسؤولة تسهم في تحقيق الرؤية الوطنية الاستباقية والطموحة للاستفادة من الذكاء الاصطناعي وبما يتماشى مع أهداف التنمية الوطنية.
الأهداف
يهدف الدليل الاسترشادي لمبادئ استخدام الذكاء الاصطناعي في الجامعات والكليات الحكومية والأهلية السعودية إلى:
تحقيق المواءمة مع التوجهات والرؤى الوطنية.
المساهمة في تعزيز جودة العملية التعليمية في مؤسسات التعليم العالي.
المساهمة في تحقيق مخرجات التعلم المستهدفة للمؤسسات التعليمية وضمان الامتثال لمعايير النزاهة الأكاديمية.
تعزيز البحث العلمي والابتكار.
تحديد أدوار ومسؤوليات أصحاب المصلحة بوضوح.
زيادة كفاءة العمليات الإدارية.
معالجة التحديات والمخاطر المحتملة.
--- الصفحة 6 ---
الإطار العام للدليل
تم تطوير هذا الدليل بما يتواءم مع الأدلة والإرشادات والسياسات الصادرة من الجهات الحكومية ذات العلاقة وتشمل: وزارة التعليم، الهيئة السعودية للبيانات والذكاء الاصطناعي (سدايا)، المركز الوطني للتعليم الإلكتروني، بالإضافة لأفضل الممارسات العالمية لاستخدامات الأدوات في المؤسسات التعليمية.
يوضح الشكل رقم 1 الإطار العام لبناء الدليل:
(وصف الشكل البياني كما ورد في النص):
الممارسات العالمية.
المركز الوطني للتعليم الإلكتروني (ضوابط واشتراطات استخدام أدوات وتطبيقات الذكاء الاصطناعي التوليدي في التعليم الرقمي).
الهيئة السعودية للبيانات والذكاء الاصطناعي SDAIA (إطار الذكاء الاصطناعي في التعليم الرقمي بالمملكة العربية السعودية، مبادئ أخلاقيات الذكاء الاصطناعي، مقدمة الذكاء الاصطناعي التوليدي للجهات الحكومية).
وزارة التعليم (دليل إرشادات استخدام الذكاء الاصطناعي التوليدي للتعليم العام).
المخرج النهائي: الدليل الاسترشادي لمبادئ استخدام الذكاء الاصطناعي في الجامعات والكليات الحكومية والأهلية السعودية (استخدام الذكاء الاصطناعي في العملية التعليمية - في البحث العلمي - في الأنشطة الإدارية).
--- الصفحة 7 ---
أخلاقيات وأبعاد استخدام الذكاء الاصطناعي في التعليم
تُبنى أخلاقيات استخدام الذكاء الاصطناعي على مجموعة من المبادئ والضوابط الواردة ضمن وثيقة مبادئ وأخلاقيات الذكاء الاصطناعي الصادرة عن الهيئة السعودية للبيانات والذكاء الاصطناعي (سدايا) والتي يجب أن تتحقق:
النزاهة والإنصاف: التأكد من عدم وجود التحيز، أو التمييز أو التنميط أو الحد منها التي يتعرض لها الأفراد أو الجماعات، أو الفئات بسبب البيانات، أو الخوارزميات ويمكن أن تؤدي إلى تمييز سلبي لفئة محددة.
الخصوصية والأمن: حماية خصوصية أصحاب البيانات الشخصية، ومعايير الأمن السيبراني ذات العلاقة بهدف منع الوصول غير المشروع إلى البيانات والنظام مما قد يؤدي إلى الإضرار بالسمعة، أو الأضرار النفسية، أو المالية أو المهنية.
الإنسانية: استخدام منهجية عادلة وأخلاقية تستند إلى حقوق الإنسان والقيم الثقافية الأساسية.
المنافع الاجتماعية والبيئية: تعزيز الأثر الإيجابي والمفيد للأولويات الاجتماعية والبيئية التي يجب أن تفيد الأفراد والمجتمع ككل، والتي تركز على الأهداف والغايات المستدامة.
الموثوقية والسلامة: ضمان المصداقية والاعتمادية التي يتمتع بها النظام من الناحية التشغيلية مع وظائفه المحددة والنتائج التي يسعى إلى تحقيقها.
الشفافية والقابلية للتفسير: أن تكون أدوات وتطبيقات الذكاء الاصطناعي ومطوروها قادرين على تبرير أسس تصميمها وممارساتها وعملياتها وخوارزمياتها وقراراتها وسلوكياتها المسموح بها أخلاقياً وغير الضارة للعامة.
المساءلة والمسؤولية: المساءلة والمسؤولية الأخلاقية عن القرارات والإجراءات التي قد تؤدي إلى مخاطر محتملة وآثار سلبية على الأفراد والمجتمعات، ويجب تطبيق الإشراف البشري والحوكمة والإدارة المناسبة عبر دورة حياة نظام الذكاء الاصطناعي بأكملها لضمان وجود آليات مناسبة لتجنب الأضرار وإساءة استخدام هذه التقنية.
ولضمان الاستخدام المسؤول للذكاء الاصطناعي في العملية التعليمية أطلق المركز الوطني للتعليم الإلكتروني في المملكة العربية السعودية إطار الذكاء الاصطناعي في التعليم الرقمي، والذي يغطي تسعة أبعاد رئيسية تتضمن (22) بُعداً فرعياً، بما يضمن الاستفادة الفعالة من دمج الذكاء الاصطناعي في العملية التعليمية.
--- الصفحة 8 ---
الفصل الأول
استخدام الذكاء الاصطناعي في العملية التعليمية
في ظل التحول الرقمي المتسارع في مجال الذكاء الاصطناعي وأدواته التي يتم استخدامها في التعليم، وتحديداً في أنشطة العملية التعليمية المختلفة (على سبيل المثال لا الحصر: تصميم المحتوى العلمي، وأنشطة القياس والتقويم).
يهدف هذا الفصل إلى توضيح ما يلي:
مبادئ استخدام الذكاء الاصطناعي في العملية التعليمية.
المعايير الاسترشادية لاستخدام الذكاء الاصطناعي في العملية التعليمية.
الأدوار والمسؤوليات عند استخدام الذكاء الاصطناعي في العملية التعليمية.
--- الصفحة 9 ---
أولاً: مبادئ استخدام الذكاء الاصطناعي في العملية التعليمية:
تهدف مبادئ استخدام الذكاء الاصطناعي في العملية التعليمية لتحقيق ما يلي:
أ - الامتثال الأخلاقي والمسؤول، ويتضمن ذلك:
تحقيق الإنصاف والعدالة وضمان الوصول المتكافئ للذكاء الاصطناعي لجميع المستفيدين، وتعزيز المساواة في الفرص.
حماية الخصوصية وأمان بيانات المستخدمين والالتزام بما ورد في نظام حماية البيانات الشخصية ولوائحه التنفيذية الصادر عن الهيئة السعودية للبيانات والذكاء الاصطناعي (سدايا).
ضمان التقيد بما ورد في ضوابط ومواصفات إدارة البيانات الوطنية وحوكمتها وحماية البيانات الشخصية الصادر عن مكتب إدارة البيانات الوطنية بالهيئة السعودية للبيانات والذكاء الاصطناعي (سدايا).
ضمان التقيد بما ورد في إطار تبني الذكاء الاصطناعي الصادر عن الهيئة السعودية للبيانات والذكاء الاصطناعي (سدايا).
ضمان الشفافية وتوفير معلومات واضحة حول كيفية استخدام الذكاء الاصطناعي وتأثيره على العملية التعليمية.
المساءلة والاستخدام المسؤول واتخاذ تدابير رقابية صارمة على استخدامات الذكاء الاصطناعي لمنع الاستخدام غير المسؤول.
حماية حقوق الملكية الفكرية واتخاذ الإجراءات والتدابير التي تضمن حماية فعالة لحقوق الملكية الفكرية لكافة أصحاب المصلحة.
ب - مراعاة الأهداف الرئيسية من الاستخدام التعليمي للذكاء الاصطناعي ويتضمن ذلك:
تحقيق المواءمة مع الأهداف التعليمية ومخرجات التعلم من خلال ربط استخدامات تطبيقات وأدوات الذكاء الاصطناعي، وأهداف ومخرجات التعلم المستهدفة بالمؤسسة التعليمية.
تمكين المتعلم كمحور للعملية من استخدامات تطبيقات وأدوات الذكاء الاصطناعي لتعزيز معارف ومهارات المتعلمين.
تمكين الكليات والأقسام والبرامج الأكاديمية من استخدام تطبيقات وأدوات الذكاء الاصطناعي في العملية التعليمية ضمن إطار مرن يتيح تصميم وتوظيف أنظمة الذكاء الاصطناعي حسب متطلبات التخصصات العلمية والعملية.
تمكين أعضاء هيئة التدريس ومن في حكمهم من اتخاذ خيارات مستنيرة عند دمج وتوظيف تطبيقات وأدوات الذكاء الاصطناعي في الممارسات التعليمية كتقنية مساندة لخبراتهم، وليس بديلاً عنها.
ضمان الأصالة والنزاهة الأكاديمية وإقرار ضوابط واضحة تضمن تحقيقها ضمن ممارسات أخلاقية في البيئة التعليمية.
تمكين المتعلمين وضمان مشاركتهم الفعالة في التجارب التعليمية وفق إرادة مستنيرة وبما يتناسب مع تخصصات واحتياجات الطلاب.
معالجة التحديات والالتزام بحماية الأمانة والأخلاقيات في البيئة التعليمية.
--- الصفحة 10 ---
ثانياً: المعايير الاسترشادية لاستخدام الذكاء الاصطناعي في العملية التعليمية:
تهدف معايير استخدام الذكاء الاصطناعي في التعليم العالي إلى تحسين التجربة التعليمية، وضمان التوافق مع مخرجات التعلم، والامتثال لمعايير النزاهة الأكاديمية، وتطبيق أفضل الممارسات والتوجيهات الوطنية، على مستوى المؤسسة التعليمية، والمستفيدين (طلبة / أعضاء هيئة التدريس ومن في حكمهم / الموظفين).
أ- المعايير الاسترشادية لاستخدام الذكاء الاصطناعي في المؤسسات التعليمية:
الالتزام بالتنسيق المسبق مع الجهات الإشرافية المعنية قبل توظيف استخدامات الذكاء الاصطناعي في العملية التعليمية.
إقرار سياسات استخدام الذكاء الاصطناعي المواءمة مع الأنظمة واللوائح والسياسات الوطنية الصادرة من الجهات ذات العلاقة ومراجعتها بشكل دوري.
التقيد بسياسة تصنيف البيانات الصادرة عن مكتب إدارة البيانات الوطنية بالهيئة السعودية للبيانات والذكاء الاصطناعي (سدايا).
إقرار خطة قياس لمتابعة مدى امتثال كافة ذوي المصلحة لضوابط وإرشادات الاستخدام الأمثل لأدوات وتطبيقات الذكاء الاصطناعي في العملية التعليمية.
تطبيق معايير الجودة لمراقبة الأثر التعليمي لأدوات وتطبيقات الذكاء الاصطناعي وتقييم فعاليتها ودمجها في السياقات التعليمية.
إعداد واعتماد مصفوفة المخاطر المحتملة المتعلقة باستخدام الذكاء الاصطناعي في العملية التعليمية.
الالتزام بالمعايير التي تضمن أن أدوات وتطبيقات الذكاء الاصطناعي تعزز مخرجات التعلم وتسهم في تحقيق أهدافها.
إقرار مبادئ توجيهية واضحة لمنسوبيها بشأن الاستخدام الأخلاقي لأدوات وتطبيقات الذكاء الاصطناعي في التعليم.
تطبيق خطة تطوير مهني لكافة منسوبيها حول استخدام أدوات وتطبيقات الذكاء الاصطناعي في عمليات التعليم والتدريب، والاستخدام الأخلاقي لها، والإمكانات، والقيود المفروضة عليها.
الالتزام بتمكين الوصول لأدوات وتطبيقات الذكاء الاصطناعي للمستفيدين داخل المؤسسة التعليمية، بما في ذلك ذوي الاحتياجات الخاصة.
ب- المعايير الاسترشادية لاستخدام أعضاء هيئة التدريس ومن في حكمهم للذكاء الاصطناعي:
التأكد من التوصيف المعتمد للمقرر والذي يوضح إمكانية استخدام أدوات الذكاء الاصطناعي في تصميم وتطوير المحتوى من عدمه.
ضمان دقة المعلومات وإجراء المراجعة الشاملة للمحتوى المنتج بواسطة الذكاء الاصطناعي لضمان الدقة والموضوعية والعدالة والشمولية.
التقييم الدقيق لكفاية وصحة مصادر المعلومات المستخدمة في تدريب نماذج الذكاء الاصطناعي، وضمان عدم محدوديتها.
--- الصفحة 11 ---
4. الإفصاح عن استخدام الذكاء الاصطناعي في إعداد المحتوى التعليمي، وتوضيح دوره.
5. التحقق من عدم مخالفة المحتوى للأنظمة واللوائح والسياسات المعتمدة في المملكة العربية السعودية.
6. الامتثال لأنظمة حماية حقوق الملكية الفكرية في المملكة العربية السعودية.
7. ضمان عدالة وسهولة الوصول لجميع الفئات المستهدفة لجميع الطلبة، بما في ذلك طلبة ذوي الاحتياجات الخاصة.
8. تطبيق أدوات التحقق من الاستلال باستخدام الذكاء الاصطناعي لضمان الامتثال لمعايير النزاهة.
9. نشر معايير الاستخدام المقبول والمسموح بشروط والاستخدام المحظور للذكاء الاصطناعي في الأنشطة التعليمية المختلفة.
10. التوعية بمنهجية توثيق المحتوى الذي تم إنشاؤه بواسطة الذكاء الاصطناعي.
ج - المعايير الاسترشادية لاستخدام الطلبة للذكاء الاصطناعي:
التقيد بالسياسات والأنظمة واللوائح المتبعة في المؤسسة التعليمية.
التقيد بالسياسات والضوابط المنظمة لاستخدام الذكاء الاصطناعي في الكيانات والمؤسسات خارج المؤسسة التعليمية كجهات التدريب الميداني.
الإفصاح عن استخدام أدوات أو تطبيقات الذكاء الاصطناعي كتابياً في الأعمال والتكاليف التي تسند إليهم.
الإفصاح عن مخرجات أدوات وتطبيقات الذكاء الاصطناعي ونسب مساهمتها فيما يتم تقديمه من أعمال متنوعة.
التقيد بنسبة التشابه بضوابط أصالة المحتوى المعتمدة في المؤسسة التعليمية عند توظيف الذكاء الاصطناعي.
استخدام أدوات وتطبيقات الذكاء الاصطناعي المرخصة من قبل المؤسسة التعليمية بهدف المحافظة على سرية وخصوصية البيانات.
عدم إدخال بيانات شخصية أو مصنفة بأي درجة من درجات السرية أو مقيدة أو مملوكة من قبل المؤسسة التعليمية بدون موافقة مسبقة من الجهات المعنية.
الالتزام بالمحافظة على خصوصية بيانات المستخدمين وأمن البيانات والالتزام بالقواعد والأنظمة واللوائح المتبعة في المؤسسة التعليمية.
--- الصفحة 12 ---
ثالثاً: الأدوار والمسؤوليات عند استخدام الذكاء الاصطناعي في العملية التعليمية:
لتحقيق نجاح تطبيق أدوات الذكاء الاصطناعي في العملية التعليمية، يوضح هذا الجزء من الفصل الأدوار والمسؤوليات لمختلف الجهات المعنية وتحديد مستوى مشاركة كل طرف وفق التوزيع التالي:
الاعتماد - Accountable (A): شخص أو جهة مسؤولة تعتمد مهمة مسندة للشخص المسؤول للموافقة عليها أو رفضها، ويتحملون المسؤولية الكاملة عن نتائجها.
المسؤولية أو الإعداد - Responsible (R): الشخص الذي ينفذ المهمة فعلياً.
التوصية - Consulted (C): المستشار الذي يقدم رأياً حول ما هو مراد تنفيذه، ويقدم الخبرة أو المشورة قبل اتخاذ القرار أو تنفيذ المهمة.
الإشعار - Informed (I): شخص يكون على علم ودراية بالمهمة ومطلع على أحدث المعلومات حول سير العمل بدون دور مباشر في التنفيذ أو الاعتماد.
جدول 1: مصفوفة المهام وتوزيع الأدوار والمسؤوليات لاستخدام الذكاء الاصطناعي في العملية التعليمية
المسؤوليات / الأدوار
الوحدة التنظيمية/اللجنة المسؤولة عن الذكاء الاصطناعي بالجامعة
وكالة الجامعة المختصة
إدارة الكلية أو العمادة
عضو هيئة التدريس
الطلبة
منح صلاحيات استخدام الذكاء الاصطناعي
C
A
I, R
I, R
I
توعية منسوبي الجهة التعليمية عن الاستخدام الأخلاقي للذكاء الاصطناعي
C
I
A
R
-
وضع معايير استخدام أدوات وتطبيقات الذكاء الاصطناعي
C
A
R
R
-
استخدام تطبيقات وأدوات الذكاء الاصطناعي والامتثال للوائح والأنظمة ذات العلاقة
I, C
A
R
R
R
التحقق من استخدام أدوات وتطبيقات الذكاء الاصطناعي من قبل الطلبة بما لا يخالف أسس النزاهة الأكاديمية
I, C
A
R
R
I
التقويم والتحسين المستمر لسياسة الذكاء الاصطناعي بالمؤسسة التعليمية
A
R
I
-
-
التحقق من التطبيق والامتثال لسياسة الذكاء الاصطناعي داخل المؤسسة التعليمية
R, C
A
R
R
-

يمكن للمؤسسة التعليمية تفويض أي دور من الأدوار الموضحة في هذا الجدول إلى الجهة التي تراها مناسبة داخلياً.


________________________________________
--- الصفحة 13 ---
الفصل الثاني
استخدام الذكاء الاصطناعي في البحث العلمي
يسهم الذكاء الاصطناعي بفاعلية في تطوير البحث العلمي وتحسين عملية تحليل البيانات، واكتشاف الأنماط المعقدة، وتسريع عملية الاستنتاج العلمي.
يهدف هذا الفصل إلى توضيح المبادئ التي تعزز ضمان النزاهة العلمية والاستخدام المسؤول عند استخدام أدوات وتطبيقات الذكاء الاصطناعي في أنشطة البحث العلمي، وتحقيق المواءمة مع السياسات الوطنية الصادرة من الجهات ذات العلاقة، وتطبيق الأنظمة ذات الصلة والامتثال للأولويات الوطنية للبحث والتطوير.
يحدد الفصل الثاني من الدليل ما يلي:
•	مبادئ استخدام الذكاء الاصطناعي في البحث العلمي.
•	المعايير الاسترشادية لاستخدام الذكاء الاصطناعي في البحث العلمي.
•	الأدوار والمسؤوليات عند استخدام الذكاء الاصطناعي في البحث العلمي.
--- الصفحة 14 ---
أولاً: مبادئ استخدام الذكاء الاصطناعي في البحث العلمي:
تهدف مبادئ استخدام الذكاء الاصطناعي في البحث العلمي إلى ضمان الاستخدام المسؤول والأخلاقي والشفاف للذكاء الاصطناعي في البحث العلمي ويتضمن ذلك:
1.	مراعاة متطلبات النزاهة الأكاديمية ومنع الانتحال أو التزوير في البحوث والدراسات.
2.	ضمان الشفافية والإفصاح عن استخدام أدوات الذكاء الاصطناعي ومنهجية توظيفها في جميع مراحل البحث العلمي.
3.	تفعيل المساءلة والمسؤولية عن نتائج الأبحاث وضمان دقتها وموثوقيتها.
4.	تحقيق حماية البيانات وأمنها عند استخدام الذكاء الاصطناعي، خاصة البيانات الحساسة والشخصية، والمشمولة بأي مستوى من مستويات الحماية.
5.	ضمان العدالة والإنصاف وتجنب التحيزات المحتملة في الذكاء الاصطناعي لضمان موثوقية النتائج.
6.	تحقيق الحماية من المخاطر المحتملة كالأخطاء أو المعلومات المضللة واتخاذ الإجراءات الوقائية لمنعها.
7.	تنمية مهارات الباحثين وقدرتهم على الاستخدام الأمثل والأخلاقي لأدوات الذكاء الاصطناعي في البحث العلمي.
8.	اتخاذ إجراءات رامية لتحقيق الامتثال للأنظمة واللوائح والتعليمات والسياسات الوطنية المنظمة لاستخدام الذكاء الاصطناعي في البحث العلمي.
ثانياً: المعايير الاسترشادية لاستخدام الذكاء الاصطناعي في البحث العلمي:
تهدف هذه الضوابط إلى توفير إطار عمل واضح وموجه للاستخدام المسؤول والفعال للذكاء الاصطناعي في البحث العلمي.
أ- المعايير الاسترشادية للمؤسسات التعليمية:
1.	التنسيق مع الجهات ذات العلاقة قبل تطبيق أدوات وتطبيقات الذكاء الاصطناعي في البحث العلمي.
2.	الالتزام بوضع معايير وإجراءات داخلية بهدف الامتثال للأنظمة واللوائح والسياسات الوطنية المتعلقة بأدوات وتطبيقات الذكاء الاصطناعي في البحث العلمي، وبما يعزز مخرجات البحث العلمي والمساهمة في تحقيق الأولويات الوطنية للبحث والتطوير والابتكار.
3.	وضع معايير للباحثين داخل المؤسسة التعليمية لما يجب الإفصاح عنه عند استخدام أدوات وتطبيقات الذكاء الاصطناعي ومن الجهة المعنية بمراجعة الإفصاح داخل المؤسسة.
4.	نشر الوعي والتثقيف المستمر حول معايير الاستخدام الأخلاقي والمسؤول لأدوات الذكاء الاصطناعي في البحث العلمي.
--- الصفحة 15 ---
5. القياس الدوري لمدى امتثال الباحثين لمعايير الاستخدام الأمثل لأدوات وتطبيقات الذكاء الاصطناعي في البحث العلمي.
6. إعداد خطط تطوير مهني للباحثين داخل المؤسسة التعليمية حول استخدام أدوات وتطبيقات الذكاء الاصطناعي في البحث العلمي، والاستخدام الأخلاقي لها، والإمكانات، والقيود المفروضة عليها.
7. إعداد واعتماد مصفوفة المخاطر المحتملة المتعلقة باستخدام الذكاء الاصطناعي في البحث العلمي.
8. تمكين الوصول لأدوات وتطبيقات الذكاء الاصطناعي في البحث العلمي للمستفيدين داخل المؤسسة التعليمية بما في ذلك ذوي الاحتياجات الخاصة.
ب - المعايير الاسترشادية للباحثين:
1.	الالتزام بالأنظمة واللوائح والتعليمات ذات الصلة بتوظيف أدوات وتطبيقات الذكاء الاصطناعي في البحث العلمي بما يعزز الاستخدام المسؤول والأمثل للذكاء الاصطناعي.
2.	التقيد بمبادئ أخلاقيات الذكاء الاصطناعي الصادر عن الهيئة السعودية للبيانات والذكاء الاصطناعي (سدايا) والمتعلقة بمنهجيات البحث والتطوير لنماذج أو أنظمة جديدة للذكاء الاصطناعي والتي تمر بها دورة حياة نظام الذكاء الاصطناعي (التخطيط والتصميم، تهيئة البيانات، البناء، قياس الأداء، التطبيق والمتابعة).
3.	يلتزم الباحثون بالإفصاح الكامل عن استخدام الذكاء الاصطناعي في أي مرحلة من مراحل البحث والإشارة بوضوح إلى الأدوات المستخدمة وطريقة تطبيقها ومراجعتها مع القسم العلمي المختص.
4.	الالتزام بمبادئ النزاهة الأكاديمية والبحثية، وتجنب الانتحال والغش، وضمان الأصالة العلمية للمخرجات البحثية.
5.	تحمل المسؤولية عن دقة وموثوقية جميع البيانات والمخرجات والمعلومات الناتجة عن استخدام أدوات الذكاء الاصطناعي في البحث العلمي.
6.	تقييم التحيزات المحتملة في خوارزميات الذكاء الاصطناعي ومجموعات البيانات المستخدمة، واتخاذ خطوات للتخفيف من هذه التحيزات لضمان العدالة والإنصاف في النتائج.
7.	الالتزام بحماية خصوصية وأمن البيانات عند استخدام الذكاء الاصطناعي عند التعامل مع البيانات الشخصية أو الحساسة، والتقيد بسياسة تصنيف البيانات الصادرة عن مكتب إدارة البيانات الوطنية بالهيئة السعودية للبيانات والذكاء الاصطناعي (سدايا).
8.	الالتزام بالمحافظة على خصوصية المستخدمين وأمن البيانات والالتزام بالقواعد والأنظمة واللوائح المتبعة في المؤسسة التعليمية.
--- الصفحة 16 ---
ثالثاً: الأدوار والمسؤوليات عند استخدام الذكاء الاصطناعي في البحث العلمي
يوضح الجدول رقم (2) مصفوفة المهام وتوزيع الأدوار والمسؤوليات لكل من الباحثين والجهات ذات العلاقة داخل المؤسسة التعليمية في سياق البحث العلمي.
جدول 2: مصفوفة المهام وتوزيع الأدوار والمسؤوليات لاستخدام الذكاء الاصطناعي في البحث العلمي
المسؤوليات / الأدوار	الوحدة التنظيمية المسؤولة عن الذكاء الاصطناعي	وكالة الجامعة (البحث العلمي)	عمادة البحث العلمي	الباحثون
منح صلاحيات استخدام الذكاء الاصطناعي في البحث العلمي	C	A	I, R	I
توعية الباحثين عن الاستخدام الأخلاقي للذكاء الاصطناعي في البحث العلمي	C	I	A	R
وضع معايير استخدام أدوات وتطبيقات الذكاء الاصطناعي في البحث العلمي	C	A	R	I
الامتثال للوائح والأنظمة ذات العلاقة عند استخدام تطبيقات وأدوات الذكاء الاصطناعي	I, C	R	R	A
التحقق من استخدام أدوات وتطبيقات الذكاء الاصطناعي من قبل الباحثين بما لا يخالف أسس النزاهة العلمية	I, C	R	R	A
التقويم والتحسين المستمر لسياسة الذكاء الاصطناعي في البحث العلمي بالمؤسسة التعليمية	A	R	I	I
التحقق من التطبيق والامتثال لسياسة الذكاء الاصطناعي في البحث العلمي داخل المؤسسة التعليمية	C	A	R	R
•	يمكن للمؤسسة التعليمية تفويض أي دور من الأدوار الموضحة في هذا الجدول إلى الجهة التي تراها مناسبة داخلياً.
--- الصفحة 17 ---
الفصل الثالث
استخدام الذكاء الاصطناعي في الأنشطة الإدارية
يسهم الذكاء الاصطناعي في رفع كفاءة الأعمال الإدارية، ويدعم تحسين جودة الخدمات المقدمة.
يوضح الفصل الثالث مبادئ ومعايير استخدام أدوات وتطبيقات الذكاء الاصطناعي في الأنشطة الإدارية داخل المؤسسات التعليمية.
يحدد هذا الفصل من الدليل ما يلي:
•	مبادئ استخدام الذكاء الاصطناعي في الأنشطة الإدارية.
•	المعايير الاسترشادية لاستخدام الذكاء الاصطناعي في الأنشطة الإدارية.
•	الأدوار والمسؤوليات لاستخدام الذكاء الاصطناعي في الأنشطة الإدارية.
--- الصفحة 18 ---
أولاً: مبادئ استخدام الذكاء الاصطناعي في الأنشطة الإدارية:
بما لا يتعارض مع الأدلة والإرشادات الصادرة من الجهات ذات العلاقة، تسعى هذه المبادئ إلى تنظيم استخدام تقنيات الذكاء الاصطناعي في المؤسسات التعليمية، من خلال:
1.	تحقيق الكفاءة والفعالية من خلال توجيه استخدام الذكاء الاصطناعي لتعزيز جودة وكفاءة العمليات الإدارية وتحسين اتخاذ القرار.
2.	تحقيق الشفافية وضمان عدالة وإنصاف استخدام أنظمة الذكاء الاصطناعي المستخدمة وتوثيق عملياتها ونتائجها بشكل يتيح المراجعة والتحقق.
3.	حماية الخصوصية وأمن البيانات وتطبيق معايير أمن البيانات الشخصية والمؤسسية.
4.	التحديد الواضح للمسؤوليات القانونية والإدارية عند استخدام تقنيات الذكاء الاصطناعي في الأنشطة الإدارية، وتفعيل آليات المراجعة والمحاسبة.
5.	التدريب والتأهيل واعتماد خطة تطوير مهني مستمرة لتدريب وتأهيل الكوادر الإدارية على استخدام هذه التقنيات بفعالية وأمان.
ثانياً: المعايير الاسترشادية لاستخدام الذكاء الاصطناعي في الأنشطة الإدارية:
لضمان الاستخدام المسؤول والفعال للذكاء الاصطناعي في الأنشطة الإدارية، تلتزم المؤسسات التعليمية بالمعايير التالية:
1.	الامتثال للأنظمة واللوائح والتعليمات والأدلة الإرشادية ذات العلاقة باستخدامات الذكاء الاصطناعي في جميع الأنشطة الإدارية بالمؤسسة.
2.	إعداد واعتماد مصفوفة المخاطر المحتملة المتعلقة باستخدام الذكاء الاصطناعي في الأنشطة الإدارية.
3.	الالتزام بضوابط شفافية وعدالة الأنظمة الإدارية المدعومة بالذكاء الاصطناعي فيما يتعلق بكيفية عمله وطريقة جمعها للبيانات ومعالجتها، وتأثيرها على القرارات.
4.	اعتبار أدوات وتطبيقات الذكاء الاصطناعي وسائل مساعدة، ويلزم الإشراف البشري المستمر كمسؤول نهائي عند اتخاذ القرارات الإدارية.
5.	ضمان أمان البيانات وحفظ الخصوصية من خلال تطبيق معايير أمن المعلومات التي تعالجها أنظمة الذكاء الاصطناعي، وضمان عدم الكشف عن البيانات الحساسة أو الشخصية دون موافقة.
6.	التدريب والتطوير المستمر وتنظيم برامج تدريبية لكافة مستويات الكادر الإداري في المؤسسة التعليمية لضمان قدرتهم على الاستخدام الفعال والمسؤول.
--- الصفحة 19 ---
7. إجراء المراجعة والتقييم الدوري لأداء أنظمة الذكاء الاصطناعي في الأنشطة الإدارية، لضمان الفعالية والدقة وتحديد التحيزات ومشكلات التطبيق.
8. الالتزام بحماية حقوق الملكية الفكرية فيما يتعلق بملكية البيانات والمخرجات التي يتم إنشاؤها بواسطة أنظمة الذكاء الاصطناعي في الأنشطة الإدارية.
ثالثاً: الأدوار والمسؤوليات لاستخدام الذكاء الاصطناعي في الأنشطة الإدارية:
يوضح جدول رقم (3) مصفوفة المهام وتوزيع الأدوار والمسؤوليات لاستخدام الذكاء الاصطناعي في الأنشطة الإدارية.
جدول 3: مصفوفة المهام وتوزيع الأدوار والمسؤوليات لاستخدام الذكاء الاصطناعي في الأنشطة الإدارية
المسؤوليات / الأدوار	الوحدة التنظيمية المسؤولة عن الذكاء الاصطناعي	وكالة الجامعة المختصة	مكتب إدارة البيانات	الموظفون والإداريون
صلاحيات استخدام الذكاء الاصطناعي في الأنشطة الإدارية	C	A	I, R	I
توعية الموظفين الإداريين عن الاستخدام الأخلاقي للذكاء الاصطناعي	C	I	A	R
وضع معايير استخدام أدوات وتطبيقات الذكاء الاصطناعي في الأنشطة الإدارية	C	A	R	I
الامتثال للوائح والأنظمة ذات العلاقة على استخدام تطبيقات وأدوات الذكاء الاصطناعي	I, C	A	R	R
التحقق من استخدام أدوات وتطبيقات الذكاء الاصطناعي بما لا يخالف أسس الشفافية والعدالة	I, C	A	R	R
التقويم والتحسين المستمر لسياسة الذكاء الاصطناعي في الأنشطة الإدارية	A	R	R	I
التحقق من التطبيق والامتثال لسياسة الذكاء الاصطناعي في الأنشطة الإدارية	R	A	A	R
(ملاحظة: في الصف الأخير، يبدو أن هناك توزيعاً مزدوجاً للمسؤولية "A" و "R" حسب سياق الجدول الأصلي، وقد تم نقلها كما وردت في المصفوفة التقديرية).
•	يمكن للمؤسسة التعليمية تفويض أي دور من الأدوار الموضحة في هذا الجدول إلى الجهة التي تراها مناسبة داخلياً.
--- الصفحة 20 ---
الفصل الرابع
المخاطر
--- الصفحة 21 ---
الفصل الرابع: المخاطر
يترتب على استخدام الذكاء الاصطناعي في المؤسسات التعليمية مخاطر تتطلب استعداداً مؤسسياً ووعياً تنظيمياً للتعامل معها بفعالية. يوضح هذا الفصل تصنيف فئات ومستويات المخاطر المرتبطة بتطوير أو استخدام تقنيات الذكاء الاصطناعي كما ورد في وثيقة أخلاقيات الذكاء الاصطناعي الصادرة عن الهيئة السعودية للبيانات والذكاء الاصطناعي (سدايا).
جدول رقم (4): مصفوفة المخاطر والإجراءات الوقائية اللازمة للمعالجة
مستوى الخطر	الوصف والإجراء
مخاطر بسيطة أو منعدمة	أنظمة الذكاء الاصطناعي التي تشكل مخاطر بسيطة أو لا تنطوي على أي مخاطر، لا يوجد عليها قيود. ويوصى بأن تكون هذه الأنظمة متوافقة مع مبادئ أخلاقيات الذكاء الاصطناعي.
مخاطر محدودة	أنظمة الذكاء الاصطناعي التي تشكل مخاطر محدودة تخضع إلى تطبيق مبادئ أخلاقيات الذكاء الاصطناعي الصادرة من الهيئة السعودية للبيانات والذكاء الاصطناعي (سدايا).
مخاطر عالية	أنظمة الذكاء الاصطناعي التي تشكل مخاطر عالية على الحقوق الأساسية للإنسان يجب أن تخضع لإجراء تقييمات ما قبل المطابقة وبعدها، ويجب أن تلتزم بأخلاقيات الذكاء الاصطناعي ويجب مراعاة المتطلبات النظامية ذات العلاقة.
مخاطر غير مقبولة	لا يسمح بأنظمة الذكاء الاصطناعي التي تشكل خطراً غير مقبول على سلامة الناس وسبل عيشهم وحقوقهم، مثل الأنظمة المتعلقة بالتصنيف الاجتماعي أو استغلال الأطفال أو تشويه السلوك الذي يحتمل أن يحدث عنها أضرار جسدية أو نفسية. وإضافة إلى الالتزام بأخلاقيات الذكاء الاصطناعي يجب مراعاة المتطلبات النظامية ذات العلاقة.
--- الصفحة 22 ---
الفصل الخامس
إرشادات استخدام الدليل
--- الصفحة 23 ---
الفصل الخامس: إرشادات استخدام الدليل
يتعين على المؤسسات التعليمية مراعاة ما يلي عند تطبيق الدليل الاسترشادي لمبادئ استخدام الذكاء الاصطناعي في الجامعات والكليات الحكومية والأهلية السعودية:
1.	إقامة ورش عمل: إقامة ورش عمل مخصصة بالتنسيق مع الجهات ذات العلاقة للفئات المشمولة بالدليل لضمان الاستخدام الوعي والمسؤول لأدوات الذكاء الاصطناعي داخل المؤسسة التعليمية.
2.	تقييم أدوات وتطبيقات الذكاء الاصطناعي: اقتراح مصفوفة لتقييم أدوات وتطبيقات الذكاء الاصطناعي التي يمكن الاستفادة منها في الاستخدامات التعليمية وتعميمها على منسوبي المؤسسة التعليمية وفق ما ورد في إطار تبني الذكاء الاصطناعي الصادر من الهيئة السعودية للبيانات والذكاء الاصطناعي (سدايا).
3.	التوعية: وضع خطة توعوية لجميع الفئات المشمولة بالدليل توضح دور إدارة الجامعة والكليات والأقسام العلمية في تعميم الدليل على منسوبيها.
4.	المراجعة والتحديث: المراجعة والتحديث بشكل مستمر لجميع السياسات والمعايير والأدوات الخاصة بالذكاء الاصطناعي بما يتوافق مع التطورات والمستجدات التقنية والأنظمة ذات العلاقة.
(يحتوي أسفل الصفحة على رسم توضيحي للعمليات الأربع: إقامة ورش عمل، تقييم الأدوات، التوعية، المراجعة والتحديث).
--- الصفحة 24 ---
والله ولي التوفيق
مجلس شؤون الجامعات
Council of Universities' Affairs
2025م
